{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data selection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the original dataset\n",
    "df = pd.read_csv('../CIC-DDoS2019.csv')\n",
    "\n",
    "# Columns to keep\n",
    "selected_columns = [\n",
    "    \"SYN Flag Count\", \"Total Fwd Packets\", \"Total Backward Packets\", \"Flow Duration\", \"Flow Packets/s\", \"Flow Bytes/s\", \n",
    "    \"Fwd Packet Length Mean\", \"Bwd Packet Length Mean\", \"Bwd IAT Mean\", \"ACK Flag Count\", \"Active Mean\", \"Inbound\",\n",
    "    \"Label\"\n",
    "]\n",
    "\n",
    "# Keep only the selected columns\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Filter by the label names BENIGN and SYN\n",
    "label_BENIGN = df[df['Label'] == 'BENIGN']\n",
    "label_SYN = df[df['Label'] == 'SYN']\n",
    "\n",
    "# Randomly sample 5000 rows from each\n",
    "sample_BENIGN = label_BENIGN.sample(n=5000, random_state=42)\n",
    "sample_SYN = label_SYN.sample(n=5000, random_state=42)\n",
    "\n",
    "# Combine and shuffle\n",
    "balanced_df = pd.concat([sample_BENIGN, sample_SYN])\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the filtered and balanced dataset\n",
    "balanced_df.to_csv('balanced_filtered_dataset.csv', index=False)\n",
    "\n",
    "print(\"Filtered and balanced dataset saved as 'balanced_filtered_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing\n",
    "\n",
    "the only pre-processing that has been done using python was to randomly select 70%, 20% and 10% for training, testing and evaluation respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Data\\SYN.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# First, split into train (70%) and temp (30%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Then, split temp into test (20%) and eval (10%)\n",
    "test_df, eval_df = train_test_split(temp_df, test_size=1/3, random_state=42, shuffle=True)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"Data\\Splits\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save each split to CSV\n",
    "train_df.to_csv(os.path.join(output_dir, \"train.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(output_dir, \"test.csv\"), index=False)\n",
    "eval_df.to_csv(os.path.join(output_dir, \"eval.csv\"), index=False)\n",
    "\n",
    "print(\"Dataset split and saved successfully:\")\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Testing set: {len(test_df)} samples\")\n",
    "print(f\"Evaluation set: {len(eval_df)} samples\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
