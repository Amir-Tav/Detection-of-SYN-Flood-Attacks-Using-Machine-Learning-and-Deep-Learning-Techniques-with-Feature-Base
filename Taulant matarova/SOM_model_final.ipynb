{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d0d34a",
   "metadata": {},
   "source": [
    "Import Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    PrecisionRecallDisplay,\n",
    "    RocCurveDisplay,\n",
    ")\n",
    "from minisom import MiniSom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6247b85",
   "metadata": {},
   "source": [
    "SOM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# trains a SOM on the input data\n",
    "def fit_som(data: np.ndarray, grid: Tuple[int, int] = (22, 22), seed: int = 42) -> MiniSom:\n",
    "    rows, cols = grid  # SOM grid dimensions set to 22x22\n",
    "    som = MiniSom(\n",
    "        x=rows, y=cols,\n",
    "        input_len=data.shape[1],         # number of features\n",
    "        sigma=3.0,                       # spread of the neighborhood\n",
    "        learning_rate=0.5,               # speed of learning\n",
    "        neighborhood_function=\"gaussian\",# type of neighborhood function\n",
    "        random_seed=seed                 # for reproducibility\n",
    "    )\n",
    "    som.random_weights_init(data)       \n",
    "    som.train_batch(data, num_iteration=10_000, verbose=False)  # train the SOM\n",
    "    return som\n",
    "\n",
    "# create a lookup table from each SOM node BMU to a majority label\n",
    "def majority_vote_lookup(som: MiniSom, data: np.ndarray, labels: np.ndarray) -> Dict[Tuple[int, int], int]:\n",
    "    vote: Dict[Tuple[int, int], List[int]] = {}\n",
    "\n",
    "    for vec, lbl in zip(data, labels):                  # go through each data point\n",
    "        bmu = som.winner(vec)                           # find best-matching unit (BMU)\n",
    "        vote.setdefault(bmu, []).append(lbl)            # collect all labels that match this BMU\n",
    "\n",
    "    # assign each BMU the most common label (rounded average)\n",
    "    return {bmu: int(round(np.mean(v))) for bmu, v in vote.items()}\n",
    "\n",
    "# predict labels for new data using the trained SOM and the vote map\n",
    "def predict_som(som: MiniSom, vote_map: Dict[Tuple[int, int], int], data: np.ndarray) -> np.ndarray:\n",
    "    # for each input vector, find its BMU and use the vote_map to assign a predicted label\n",
    "    return np.array([vote_map.get(som.winner(v), 0) for v in data])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c16c6",
   "metadata": {},
   "source": [
    "K-folds and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa37621",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# performs cross-validation on k-folds using a Self-Organizing Map (SOM)\n",
    "def som_cross_validate(Syn_df: pd.DataFrame, feature_columns: List[str], grid: Tuple[int, int] = (22,22)):\n",
    "    accuracies = []\n",
    "    all_true   = []  # collect true labels across folds\n",
    "    all_pred   = []  # collect predicted labels across folds\n",
    "    all_scores = []  # collect confidence scores across folds\n",
    "\n",
    "    # Loop over each fold in the dataset\n",
    "    for fold in sorted(Syn_df[\"Fold\"].unique()):\n",
    "        print(f\"Fold {fold+1} / {Syn_df['Fold'].nunique()}\")\n",
    "\n",
    "        # Split into training and validation sets\n",
    "        train_df    = Syn_df[Syn_df[\"Fold\"] != fold]\n",
    "        validate_df = Syn_df[Syn_df[\"Fold\"] == fold]\n",
    "\n",
    "        # Scale features\n",
    "        standard_scaler = StandardScaler()\n",
    "        X_train = standard_scaler.fit_transform(train_df[feature_columns])\n",
    "        X_validate = standard_scaler.transform(validate_df[feature_columns])\n",
    "        y_train = train_df[\"Label\"].values\n",
    "        y_validate = validate_df[\"Label\"].values\n",
    "\n",
    "        # train SOM and assign labels to nodes via majority voting\n",
    "        som      = fit_som(X_train, grid)\n",
    "        vote_map = majority_vote_lookup(som, X_train, y_train)\n",
    "        \n",
    "        # predict labels for validation set\n",
    "        y_predict = predict_som(som, vote_map, X_validate)\n",
    "\n",
    "        # confidence score = negative quantization error\n",
    "        scores = [-som.quantization_error(np.array([v])) for v in X_validate]\n",
    "\n",
    "        # collect for visual diagnostics\n",
    "        all_true.extend(y_validate)\n",
    "        all_pred.extend(y_predict)\n",
    "        all_scores.extend(scores)\n",
    "\n",
    "        # accuracy\n",
    "        acc = (y_predict == y_validate).mean()\n",
    "        accuracies.append(float(acc))\n",
    "        print(f\"Fold {fold+1}: accuracy = {acc:.4f}\")\n",
    "\n",
    "    # summary of final results\n",
    "    print(\"\\n══════ SOM Validation Summary ══════\")\n",
    "    for i, a in enumerate(accuracies, 1):\n",
    "        print(f\"Fold {i}: {a:.4f}\")\n",
    "    print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")\n",
    "    print(f\"Standard Deviation: {np.std(accuracies):.4f}\")\n",
    "\n",
    "    # Visual evaluation (from cross-validation only)\n",
    "    cm = confusion_matrix(all_true, all_pred)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix (CV)\")\n",
    "    plt.show()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(all_true, all_scores)\n",
    "    roc_auc     = auc(fpr, tpr)\n",
    "    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc).plot()\n",
    "    plt.title(f\"ROC Curve (CV) (AUC = {roc_auc:.4f})\")\n",
    "    plt.show()\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(all_true, all_scores)\n",
    "    PrecisionRecallDisplay(precision=precision, recall=recall).plot()\n",
    "    plt.title(\"Precision-Recall Curve (CV)\")\n",
    "    plt.show()\n",
    "\n",
    "    return accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceaa3aa",
   "metadata": {},
   "source": [
    "Results and running it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56985e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the dataset\n",
    "    Syn_df = pd.read_csv(\"D:\\Coding Projects\\Detection-of-SYN-Flood-Attacks-Using-Machine-Learning-and-Deep-Learning-Techniques-with-Feature-Base\\Data\\K5_Dataset.csv\")\n",
    "\n",
    "    # select first 12 feature columns (exclude label and fold info)\n",
    "    feature_columns = Syn_df.columns.difference([\"Label\", \"Fold\"]).tolist()[:12]\n",
    "\n",
    "    # run cross-validation using a Self-Organizing Map\n",
    "    accs = som_cross_validate(Syn_df, feature_columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
